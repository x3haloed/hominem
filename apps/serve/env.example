# Hominem Serving System Environment Configuration

# Database Configuration
# Path to SQLite database file (will be created if it doesn't exist)
DATABASE_PATH=storage/conversations.db

# Server Configuration
PORT=8000
HOST=0.0.0.0

# Model Configuration
# Base model path (leave empty to auto-detect from LoRA)
BASE_MODEL_PATH=

# Auto-Load LoRA Model on Startup
# This tells the server which LoRA model to load automatically when it starts
# The server will look in artifacts/lora/{AUTO_LOAD_LORA}/ for the LoRA adapter
# Examples:
# - "qwen3.1-7b" (for your current training)
# - "default" (if you have a default LoRA)
# - Full absolute path to LoRA directory
# Leave empty to start without auto-loading (you can load manually via UI)
AUTO_LOAD_LORA=qwen3.1-7b

# Model parameters
MODEL_TEMPERATURE=0.7
MAX_TOKENS=2048

# Development
DEBUG=true

# Self-Awareness Configuration
ENABLE_SELF_AWARENESS=true
SELF_AWARENESS_MAX_INTROSPECTION_LINES=16
SELF_AWARENESS_ENABLE_PERSPECTIVE_GATE=true
SELF_AWARENESS_PERSPECTIVE_GATE_ASYNC=false
SELF_AWARENESS_USE_FAST_MODEL=false
SELF_AWARENESS_TOKEN=<SELF>
SELF_AWARENESS_MAX_INTENSITY=5.0
SELF_AWARENESS_NOVELTY_THRESHOLD=0.85
SELF_AWARENESS_PRUNE_AGE_DAYS=30
SELF_AWARENESS_KEEP_RECENT=100
