# Hominem Serving System Environment Configuration

# Database Configuration
# Path to SQLite database file (will be created if it doesn't exist)
DATABASE_PATH=storage/conversations.db

# Server Configuration
PORT=8000
HOST=0.0.0.0

# Model Configuration
# Base model path (leave empty to auto-detect from LoRA)
BASE_MODEL_PATH=

# Auto-Load LoRA Model on Startup
# This tells the server which LoRA model to load automatically when it starts
# The server will look in artifacts/lora/{AUTO_LOAD_LORA}/ for the LoRA adapter
# Examples:
# - "qwen3.1-7b" (for your current training)
# - "default" (if you have a default LoRA)
# - Full absolute path to LoRA directory
# Leave empty to start without auto-loading (you can load manually via UI)
AUTO_LOAD_LORA=qwen3.1-7b

# Model parameters
MODEL_TEMPERATURE=0.7
MAX_TOKENS=2048

# Development
DEBUG=true

# Self-Awareness Configuration
ENABLE_SELF_AWARENESS=true
SELF_AWARENESS_MAX_INTROSPECTION_LINES=16
SELF_AWARENESS_ENABLE_PERSPECTIVE_GATE=true
SELF_AWARENESS_PERSPECTIVE_GATE_ASYNC=false
SELF_AWARENESS_USE_FAST_MODEL=false
SELF_AWARENESS_TOKEN=<SELF>
SELF_AWARENESS_MAX_INTENSITY=5.0
SELF_AWARENESS_NOVELTY_THRESHOLD=0.85
SELF_AWARENESS_PRUNE_AGE_DAYS=30
SELF_AWARENESS_KEEP_RECENT=100

# Emotion Engine
ENABLE_EMOTION_ENGINE=true
EMOTION_LABELING_TIMEOUT=30
EMOTION_LABELING_MAX_RETRIES=2
INFERENCE_EMOTION_LABEL_API_KEY=your_openrouter_api_key_here

# Prompt bootstrap (NOT saved to DB; only prepended to the model prompt)
# JSON string: appended to system prompt
# HOMINEM_BOOTSTRAP_MESSAGES_JSON="You are Hominem. Be concise, concrete, and kind."
#
# Or JSON list of message objects. "system" entries append to system prompt; "user"/"assistant"
# entries become prefix turns inserted before DB-backed conversation history.
# Note: keep it on ONE line, and escape inner quotes.
# HOMINEM_BOOTSTRAP_MESSAGES_JSON="[{\"role\":\"system\",\"content\":\"You are Hominem. Be concise, concrete, and kind.\"},{\"role\":\"user\",\"content\":\"Before we start: what should I know about talking to you?\"},{\"role\":\"assistant\",\"content\":\"Be direct. If you're unsure, say so. I'll ask clarifying questions when needed.\"}]"
# HOMINEM_BOOTSTRAP_MESSAGES_JSON=

# Debugging: dump the FULL post-template prompt to server logs on every completion
# Warning: includes user content and can be very large/noisy.
HOMINEM_DUMP_FULL_PROMPT=false

# Control scripts (optional)
# Used by apps/cli/boot_model.py and apps/cli/stop_model.py
# HOMINEM_SERVE_PID_FILE=storage/hominem_serve.pid
# HOMINEM_SERVE_ENV_FILE=.env
# HOMINEM_SERVE_LOG_LEVEL=info