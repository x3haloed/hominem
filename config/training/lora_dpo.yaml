model:
  # Base causal LM to adapt with LoRA.
  # You can swap this to any HF CausalLM (e.g., "gpt2", "meta-llama/Llama-3.2-1B-Instruct").
  base_model_id: "gpt2"
  max_length: 512
  padding_side: "left"
  use_4bit: false

lora:
  r: 8
  alpha: 16
  dropout: 0.05
  bias: "none"
  # For many decoder-only models these target modules are typical; adjust per model if needed.
  target_modules:
    - "c_attn"
    - "c_proj"

training:
  preferences_path: "data/preferences/preferences.jsonl"
  output_dir: "artifacts/lora/default"
  batch_size: 2
  num_epochs: 1
  learning_rate: 5.0e-5
  warmup_steps: 0
  max_grad_norm: 1.0
  logging_steps: 10
  save_every_steps: 0   # 0 = only save at end
  beta: 0.1             # DPO-style temperature coefficient
  seed: 42


